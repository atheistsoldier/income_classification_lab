# -*- coding: utf-8 -*-
"""Machine Learning Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1heHOGo5SPNlMiHoKHY43rC-sLGSdqzmo
"""

import numpy as np
import pandas as pd
from scipy import stats
import pickle

# Read Dataset
df = pd.read_csv('./income_evaluation.csv')
df.columns = list(map(lambda a: a.lstrip(), df.columns))


missing_count = {}
for column in df.columns:
    df[column].replace(' ?', np.NaN, inplace=True)
    missing_count[column] = df[column].isna().sum()


"""## Count Numerical & Categorical Features"""

numerical_features=[features for features in df.columns if df[features].dtype!='O']
categorical_features = [features for features in df.columns if df[features].dtype == 'O']

print("Numerical Features: ", ', '.join(numerical_features), "\nCategorical Features: ", ', '.join(categorical_features))

"""## Continuous and Discrete Features"""

continuous_features=[features for features in numerical_features if len(pd.unique(df[features]))>25]
discrete_features=[features for features in numerical_features if len(pd.unique(df[features]))<=25]
print("Continuous Features: ", ', '.join(continuous_features), "\nDiscrete Features: ", ', '.join(discrete_features))






"""# Feature Engineering

# Replace none values
"""

df_modified=df
for col in numerical_features:
  df_modified[col].replace( np.NaN, df.median(axis=0,skipna=True)[col],inplace=True)

for col in categorical_features:
  df_modified[col].replace( np.NaN, df.mode()[col][0],inplace=True)

"""## Replace categorical features with numerical values"""

df_cat_to_num=pd.get_dummies(df_modified)

df_cat_to_num

"""## Using boxcox to normalise data"""

df_normalized=df_cat_to_num
df_normalized['capital-gain']=df_normalized['capital-gain']+5
df_normalized['capital-loss']=df_normalized['capital-loss']+5
for feature in continuous_features:
    df_normalized[feature] = pd.DataFrame(stats.boxcox(df_normalized[feature])[0])


"""## Removing outliers"""

for feature in numerical_features:
    q75,q25 = np.percentile(df_normalized.loc[:,feature],[75,25])
    intr_qr = q75-q25
 
    max_range= q75+(1.5*intr_qr)
    min_range = q25-(1.5*intr_qr)
    
    df_normalized[feature].values[df_normalized[feature].values < min_range] = min_range
    df_normalized[feature].values[df_normalized[feature].values > max_range] = max_range

df_normalized






X = df_normalized.drop(columns=['income_ >50K', 'income_ <=50K'])
y = df_normalized['income_ >50K']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

print(X_test.columns)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
score_list = []
solvers={'newton-cg':['l2','none'],'lbfgs': ['l2', 'none'],'liblinear':['l1', 'l2'],'sag':['l2', 'none'],'saga':['elasticnet', 'l1', 'l2', 'none']}

logistic_regression = LogisticRegression(penalty='l2', solver='liblinear')
  
logistic_regression.fit(X_train, y_train)
filename = 'finalized_model.sav'
pickle.dump(logistic_regression, open(filename, 'wb'))
loaded_model = pickle.load(open(filename, 'rb'))
columns=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']
inp=[76, ' Private',124191, ' Masters',14, ' Married-civ-spouse', ' Exec-managerial', ' Husband', ' White', ' Male',0,0,40, ' United-States']

inp_data={}
i=0
print(loaded_model.feature_names_in_)
for col in columns:
  inp_data[col]=[inp[i]]
  i=i+1
inp_data=pd.DataFrame(inp_data)
inp_data=pd.get_dummies(inp_data)
print(type(inp_data))
df_modified_inp=pd.DataFrame()
for col in df_normalized.columns:
  df_modified_inp[col]=[0]
for col in inp_data:
  df_modified_inp[col]=inp_data[col]
df_modified_inp['capital-gain']=df_modified_inp['capital-gain']+5
df_modified_inp['capital-loss']=df_modified_inp['capital-loss']+5

df_modified_inp.drop(columns=['income_ >50K', 'income_ <=50K'],inplace=True)

y_predict = loaded_model.predict(df_modified_inp)
print(y_predict)
      
    





